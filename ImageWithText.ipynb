{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import PIL\n",
    "import io\n",
    "from keras.applications import resnet50\n",
    "import h5py\n",
    "import matplotlib.image as mat_img\n",
    "from PIL import Image\n",
    "import urllib.request\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=pd.read_excel('Training_Data.xlsx')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Save training images\n",
    "#def save_images(url):\n",
    "#    import re\n",
    "#    import os\n",
    "#    with urllib.request.urlopen(url) as URL:\n",
    "#        with open('temp.jpg','wb') as f:\n",
    "#            f.write(URL.read())\n",
    "#        img=Image.open('temp.jpg').convert('RGB')\n",
    "#        img=img.resize((224,224))\n",
    "#        category=train_df[train_df['ImageUrl']==url]['CategoryName'].tolist()[0]\n",
    "#        if os.path.isdir('train_images/'+category) == False:\n",
    "#            os.makedirs('train_images/'+category)\n",
    "#        img.save('train_images/'+category+'/'+url.split('/')[-1])\n",
    "#    return train_df[train_df['ImageUrl']==url]['Title'].tolist()[0]\n",
    "#title = train_df['ImageUrl'].map(save_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "data_dir = pathlib.Path('train_images')\n",
    "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
    "print(image_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_name(path):\n",
    "    return path.split('/')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df['Name']=train_df['ImageUrl'].map(get_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.data.ops import dataset_ops\n",
    "from tensorflow.python.keras.layers.preprocessing import image_preprocessing\n",
    "from tensorflow.python.keras.preprocessing import dataset_utils\n",
    "from tensorflow.python.ops import image_ops\n",
    "from tensorflow.python.ops import io_ops\n",
    "from tensorflow.python.util.tf_export import keras_export\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import scipy\n",
    "\n",
    "\n",
    "ALLOWLIST_FORMATS = ('.bmp', '.gif', '.jpeg', '.jpg', '.png')\n",
    "\n",
    "def image_dataset_from_directory(directory,dataframe,\n",
    "                                 labels='inferred',\n",
    "                                 label_mode='int',\n",
    "                                 class_names=None,\n",
    "                                 color_mode='rgb',\n",
    "                                 batch_size=32,\n",
    "                                 image_size=(256, 256),\n",
    "                                 shuffle=True,\n",
    "                                 seed=None,\n",
    "                                 validation_split=None,\n",
    "                                 subset=None,\n",
    "                                 interpolation='bilinear',\n",
    "                                 follow_links=False):\n",
    "\n",
    "    if labels != 'inferred':\n",
    "        if not isinstance(labels, (list, tuple)):\n",
    "            raise ValueError(\n",
    "                  '`labels` argument should be a list/tuple of integer labels, of '\n",
    "                  'the same size as the number of image files in the target '\n",
    "                  'directory. If you wish to infer the labels from the subdirectory '\n",
    "                  'names in the target directory, pass `labels=\"inferred\"`. '\n",
    "                  'If you wish to get a dataset that only contains images '\n",
    "                  '(no labels), pass `label_mode=None`.')\n",
    "        if class_names:\n",
    "              raise ValueError('You can only pass `class_names` if the labels are '\n",
    "                               'inferred from the subdirectory names in the target '\n",
    "                               'directory (`labels=\"inferred\"`).')\n",
    "    if label_mode not in {'int', 'categorical', 'binary', None}:\n",
    "        raise ValueError(\n",
    "            '`label_mode` argument must be one of \"int\", \"categorical\", \"binary\", '\n",
    "            'or None. Received: %s' % (label_mode,))\n",
    "    if color_mode == 'rgb':\n",
    "        num_channels = 3\n",
    "    elif color_mode == 'rgba':\n",
    "        num_channels = 4\n",
    "    elif color_mode == 'grayscale':\n",
    "        num_channels = 1\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            '`color_mode` must be one of {\"rbg\", \"rgba\", \"grayscale\"}. '\n",
    "            'Received: %s' % (color_mode,))\n",
    "    interpolation = image_preprocessing.get_interpolation(interpolation)\n",
    "    dataset_utils.check_validation_split_arg(\n",
    "        validation_split, subset, shuffle, seed)\n",
    "\n",
    "    if seed is None:\n",
    "        seed = np.random.randint(1e6)\n",
    "    image_paths, labels, class_names = dataset_utils.index_directory(\n",
    "        directory,\n",
    "        labels,\n",
    "        formats=ALLOWLIST_FORMATS,\n",
    "        class_names=class_names,\n",
    "        shuffle=shuffle,\n",
    "        seed=seed,\n",
    "        follow_links=follow_links)\n",
    "\n",
    "    if label_mode == 'binary' and len(class_names) != 2:\n",
    "        raise ValueError(\n",
    "            'When passing `label_mode=\"binary\", there must exactly 2 classes. '\n",
    "            'Found the following classes: %s' % (class_names,))\n",
    "\n",
    "    image_paths, labels = dataset_utils.get_training_or_validation_split(\n",
    "        image_paths, labels, validation_split, subset)\n",
    "    \n",
    "    img_ds,text_ds,label_ds = paths_and_labels_to_dataset(\n",
    "        image_paths=image_paths,\n",
    "        image_size=image_size,\n",
    "        num_channels=num_channels,\n",
    "        labels=labels,\n",
    "        label_mode=label_mode,\n",
    "        num_classes=len(class_names),\n",
    "        interpolation=interpolation,\n",
    "        df=dataframe)\n",
    "    #if shuffle:\n",
    "    #    # Shuffle locally at each iteration\n",
    "    #    img_ds = img_ds.shuffle(buffer_size=batch_size * 8, seed=seed)\n",
    "    #    text_ds = text_ds.shuffle(buffer_size=batch_size * 8, seed=seed)\n",
    "    #    label_ds = label_ds.shuffle(buffer_size=batch_size * 8, seed=seed)\n",
    "    #img_ds = img_ds.batch(batch_size)\n",
    "    #text_ds = text_ds.batch(batch_size)\n",
    "    #label_ds = label_ds.batch(batch_size)\n",
    "    # Users may need to reference `class_names`.\n",
    "    #label_ds.class_names = class_names\n",
    "    # Include file paths for images as attribute.\n",
    "    #img_ds.file_paths = image_paths\n",
    "    return img_ds,text_ds,label_ds\n",
    "\n",
    "\n",
    "def paths_and_labels_to_dataset(image_paths,\n",
    "                                image_size,\n",
    "                                num_channels,\n",
    "                                labels,\n",
    "                                label_mode,\n",
    "                                num_classes,\n",
    "                                interpolation,\n",
    "                                df):\n",
    "    # TODO(fchollet): consider making num_parallel_calls settable\n",
    "    path_ds = dataset_ops.Dataset.from_tensor_slices(image_paths)\n",
    "    \n",
    "    text_vectorizer = tf.keras.layers.experimental.preprocessing.TextVectorization(output_mode=\"tf-idf\")\n",
    "    text_vectorizer.adapt(df['Title'].tolist())\n",
    "    \n",
    "    text_list = [get_text(image_paths[i],df) for i in range(len(image_paths))]\n",
    "    text_ds = np.array([sum(text_vectorizer(i)).numpy() for i in text_list])#dataset_ops.Dataset.from_tensor_slices(text_list)\n",
    "    img_ds = np.array([path_to_image(image_paths[i],image_size,num_channels,interpolation).numpy() for i in range(len(image_paths))])#path_ds.map(lambda x: path_to_image(x, image_size, num_channels, interpolation))\n",
    "    if label_mode:\n",
    "        label_ds = np.array([tf.one_hot(i,63).numpy() for i in labels])#dataset_utils.labels_to_dataset(labels, label_mode, num_classes)\n",
    "        #img_txt_ds = dataset_ops.Dataset.zip((img_ds,text_ds))\n",
    "        #img_txt_ds = dataset_ops.Dataset.zip((img_txt_ds,label_ds))\n",
    "    return img_ds,text_ds,label_ds\n",
    "\n",
    "\n",
    "def path_to_image(path, image_size, num_channels, interpolation):\n",
    "    img = io_ops.read_file(path)\n",
    "    img = image_ops.decode_image(\n",
    "        img, channels=num_channels, expand_animations=False)\n",
    "    img = image_ops.resize_images_v2(img, image_size, method=interpolation)\n",
    "    img.set_shape((image_size[0], image_size[1], num_channels))\n",
    "    return img\n",
    "\n",
    "def get_text(path,df):\n",
    "    path = pathlib.Path(path)\n",
    "    name = path.parts[-1]\n",
    "    text = df[df['Name']==name]['Title'].to_string(index=False)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "img_height = 224\n",
    "img_width = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_ds,train_text_ds,train_label_ds = image_dataset_from_directory(\n",
    "            data_dir,dataframe = train_df,\n",
    "            validation_split=0.2,\n",
    "            subset = \"training\",\n",
    "            seed = 123,\n",
    "            image_size = (img_height,img_width),\n",
    "            batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_img_ds,val_text_ds,val_label_ds = image_dataset_from_directory(\n",
    "            data_dir,dataframe = train_df,\n",
    "            validation_split=0.2,\n",
    "            subset = \"validation\",\n",
    "            seed = 123,\n",
    "            image_size = (img_height,img_width),\n",
    "            batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_input = tf.keras.applications.resnet_v2.preprocess_input\n",
    "image_size = (img_height,img_width)\n",
    "image_shape = image_size+(3,)\n",
    "base_model = tf.keras.applications.ResNet50V2(input_shape=image_shape,\n",
    "                                              include_top=False,weights='imagenet')\n",
    "base_model.trainable = False\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_inputs = tf.keras.Input(shape=(224, 224, 3))\n",
    "img = preprocess_input(img_inputs)\n",
    "img = base_model(img, training=False)\n",
    "img = global_average_layer(img)\n",
    "img = tf.keras.Model(inputs=img_inputs,outputs=img)\n",
    "\n",
    "txt_inputs = tf.keras.Input(shape=(13512))\n",
    "txt = tf.keras.layers.Dense(1)(txt_inputs)\n",
    "txt = tf.keras.Model(inputs=txt_inputs,outputs=txt)\n",
    "\n",
    "x = tf.keras.layers.concatenate([img.output,txt.output])\n",
    "\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "outputs = tf.keras.layers.Dense(63)(x)\n",
    "model = tf.keras.Model(inputs = [img.input,txt.input], outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_learning_rate = 0.0001\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=base_learning_rate),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x=[train_img_ds, train_text_ds], y=train_label_ds,\n",
    "          validation_data=([val_img_ds, val_text_ds], val_label_ds),epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
